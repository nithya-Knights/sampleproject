name: Enhanced Security Pipeline

on:
  push:
    branches:
      - test-semgrep-improvements
  pull_request:
    branches:
      - test-semgrep-improvements

permissions:
  contents: read
  actions: read
  security-events: write

# Prevent multiple runs on same PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  security-tests:
    name: Security & Configuration Tests
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1 (pinned SHA)
        with:
          fetch-depth: 0

      # ========== PYTHON SETUP WITH CACHING ==========
      - name: Set up Python
        uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4.7.1
        with:
          python-version: '3.12.9'
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Cache Python packages
        uses: actions/cache@704facf57e6136b1bc63b828d79edcd491f0ee84  # v3.3.2
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov coverage pytest-asyncio httpx

      # ========== CONFIGURATION VALIDATION (FMEA-DOTENV-002/003/004) ==========
      - name: Validate Environment Configuration
        run: |
          python3 - <<'EOF'
          import os
          import sys
          from pathlib import Path

          # Check required environment variables exist
          required_vars = [
              'DATABASE_URL',
              'SECRET_KEY',
              'API_KEY'
          ]
          
          # For demo, we'll check if .env.example exists
          env_example = Path('.env.example')
          if not env_example.exists():
              print("⚠️ No .env.example file found")
          
          # Verify .env is in .gitignore
          gitignore = Path('.gitignore')
          if gitignore.exists():
              content = gitignore.read_text()
              if '.env' not in content:
                  print("❌ .env must be in .gitignore")
                  sys.exit(1)
              print("✅ .env is properly ignored")
          
          # Check .dockerignore if Dockerfile exists
          if Path('Dockerfile').exists():
              dockerignore = Path('.dockerignore')
              if dockerignore.exists():
                  content = dockerignore.read_text()
                  if '.env' not in content:
                      print("❌ .env must be in .dockerignore")
                      sys.exit(1)
                  print("✅ .env excluded from Docker builds")
          
          print("✅ Configuration validation passed")
          EOF

      # ========== ERROR HANDLING VALIDATION (OTS-RSK-00048) ==========
      - name: Validate Production Configuration Safety
        run: |
          python3 - <<'EOF'
          import sys
          try:
              # Check if config module exists
              from app.config import settings
              
              # Verify debug mode is disabled
              if hasattr(settings, 'DEBUG') and settings.DEBUG:
                  print("❌ DEBUG mode must be False in production")
                  sys.exit(1)
              
              print("✅ Production configuration validated")
          except ImportError:
              print("⚠️ Config module not found, skipping validation")
          except Exception as e:
              print(f"⚠️ Configuration check error: {e}")
          EOF

      # ========== SECURITY AUTHENTICATION TESTS (OTS-RSK-00047) ==========
      - name: Run Security Authentication Tests
        run: |
          # Create test directory if it doesn't exist
          mkdir -p tests/security
          
          # Run authentication tests if they exist
          if [ -d "tests/security" ] && [ "$(ls -A tests/security/test_*.py 2>/dev/null)" ]; then
            pytest tests/security/ -v \
              --junitxml=test-results/security-auth.xml \
              -m "security or auth" || echo "⚠️ Security tests need implementation"
          else
            echo "⚠️ Security tests not yet implemented at tests/security/"
            echo "Required: Tests for 401/403 responses, RBAC enforcement"
          fi

      # ========== BLOCK PSYCOPG2-BINARY (FMEA-PSYCOPG-001) ==========
      - name: Block psycopg2-binary in Production
        run: |
          if grep -q "psycopg2-binary" requirements.txt; then
            echo "❌ CRITICAL: psycopg2-binary found in requirements.txt"
            echo "Production must use source-built psycopg2 for stability and security"
            exit 1
          fi
          echo "✅ No psycopg2-binary in production dependencies"

      # ========== NUMPY PICKLE VULNERABILITY (FMEA-NUMPY-003) ==========
      - name: Detect Unsafe NumPy Pickle Usage
        run: |
          echo "Scanning for unsafe NumPy allow_pickle=True usage..."
          
          # Search for allow_pickle=True in source code
          if grep -rn "allow_pickle=True" app/ 2>/dev/null; then
            echo "❌ CRITICAL: Found allow_pickle=True usage"
            echo "This allows arbitrary code execution via malicious pickle files"
            exit 1
          fi
          
          # Also check for np.load without explicit allow_pickle=False
          if grep -rn "np\.load(" app/ 2>/dev/null | grep -v "allow_pickle=False"; then
            echo "⚠️ WARNING: Found np.load() without explicit allow_pickle=False"
            echo "Consider adding allow_pickle=False for security"
          fi
          
          echo "✅ No unsafe NumPy pickle usage detected"

      # ========== RUN TESTS WITH COVERAGE ==========
      - name: Run Tests and Generate Coverage Report
        run: |
          pytest --cov=app --cov-report=xml --cov-report=term \
            --junitxml=test-results/pytest.xml || true

      # ========== DATABASE RESILIENCE TESTS (FMEA-PSYCOPG-004) ==========
      - name: Run Database Resilience Tests
        run: |
          if [ -d "tests/database" ] && [ "$(ls -A tests/database/test_*.py 2>/dev/null)" ]; then
            pytest tests/database/ -v \
              --junitxml=test-results/database-resilience.xml || \
              echo "⚠️ Database resilience tests need implementation"
          else
            echo "⚠️ Database resilience tests not implemented"
            echo "Required: Connection retry, pooling, transaction rollback tests"
          fi

  # ========== OPENAPI SCHEMA VALIDATION (OTS-RSK-00049) ==========
  api-contract-validation:
    name: API Contract & Schema Validation
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236
        with:
          python-version: '3.12.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install openapi-spec-validator

      - name: Generate Current OpenAPI Schema
        run: |
          # Generate OpenAPI schema from your FastAPI app
          python3 - <<'EOF'
          import json
          try:
              from app.main import app
              schema = app.openapi()
              with open('openapi-current.json', 'w') as f:
                  json.dump(schema, f, indent=2)
              print("✅ Generated current OpenAPI schema")
          except Exception as e:
              print(f"⚠️ Could not generate schema: {e}")
              # Create empty schema to prevent pipeline failure
              with open('openapi-current.json', 'w') as f:
                  json.dump({"openapi": "3.0.0", "info": {"title": "API", "version": "1.0.0"}}, f)
          EOF

      - name: Validate OpenAPI Schema
        uses: thiyagu06/openapi-validator-action@bde58b93677c527290028f2a4c9cc279bffb37a1  # v1
        with:
          filepath: 'openapi-current.json'
        continue-on-error: true

      - name: Check for Breaking Changes
        run: |
          # If baseline exists, compare for breaking changes
          if [ -f "openapi-baseline.json" ]; then
            pip install openapi-diff || pip install json-schema-diff
            echo "⚠️ OpenAPI baseline comparison not yet implemented"
            echo "Store openapi-baseline.json in repo for breaking change detection"
          else
            echo "ℹ️ No baseline schema found - saving current as baseline"
            cp openapi-current.json openapi-baseline.json
          fi

      - name: Run API Contract Tests
        run: |
          if [ -d "tests/contract" ] && [ "$(ls -A tests/contract/test_*.py 2>/dev/null)" ]; then
            pip install pytest httpx
            pytest tests/contract/ -v \
              --junitxml=test-results/api-contract.xml || \
              echo "⚠️ API contract tests need implementation"
          else
            echo "⚠️ API contract tests not implemented"
            echo "Required: Status codes, response formats, data types validation"
          fi

  # ========== SECURITY SCANNING ==========
  security-scanning:
    name: Security Scanning (SAST, SCA, Secrets)
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236
        with:
          python-version: '3.12.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ========== GITLEAKS SECRET SCAN (FMEA-DOTENV-002/003/004) ==========
      - name: Run Gitleaks Secret Scan
        uses: gitleaks/gitleaks-action@cb7149d7cfbc7f9f2036c3c7c4e4fd5a39859146  # v2.3.2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # ========== SAFETY VULNERABILITY SCAN (OTS-RSK-00053) ==========
      - name: Run Safety Vulnerability Scan
        uses: pyupio/safety-action@1cef06ef64085dcd7b5ccf79449a57fc0697d8e9  # v1
        with:
          api-key: ${{ secrets.SAFETY_API_KEY }}
        continue-on-error: true

      - name: Run Safety CLI Scan (Fallback)
        if: ${{ !secrets.SAFETY_API_KEY }}
        run: |
          pip install safety
          mkdir -p safety-results
          
          # Run Safety scan and save results
          safety check --json --output safety-results/safety-report.json || true
          
          # Check for HIGH/CRITICAL vulnerabilities
          if [ -f safety-results/safety-report.json ]; then
            python3 - <<'EOF'
          import json
          import sys
          
          try:
              with open('safety-results/safety-report.json') as f:
                  data = json.load(f)
              
              vulnerabilities = data.get('vulnerabilities', [])
              critical_count = sum(1 for v in vulnerabilities 
                                   if v.get('severity', '').upper() in ['CRITICAL', 'HIGH'])
              
              print(f"Total vulnerabilities: {len(vulnerabilities)}")
              print(f"HIGH/CRITICAL vulnerabilities: {critical_count}")
              
              if critical_count > 0:
                  print(f"❌ Found {critical_count} HIGH/CRITICAL vulnerabilities")
                  for v in vulnerabilities:
                      if v.get('severity', '').upper() in ['CRITICAL', 'HIGH']:
                          print(f"  - {v.get('package')}: {v.get('vulnerability')}")
                  sys.exit(1)
              else:
                  print("✅ No HIGH/CRITICAL vulnerabilities found")
          except Exception as e:
              print(f"⚠️ Error parsing Safety results: {e}")
          EOF
          fi

      # ========== SNYK SCAN ==========
      - name: Cache Snyk CLI
        uses: actions/cache@704facf57e6136b1bc63b828d79edcd491f0ee84
        with:
          path: /usr/local/bin/snyk
          key: snyk-cli-${{ runner.os }}

      - name: Install Snyk CLI
        run: |
          if [ ! -f /usr/local/bin/snyk ]; then
            curl -Lo snyk https://static.snyk.io/cli/latest/snyk-linux
            chmod +x snyk
            sudo mv snyk /usr/local/bin/snyk
          fi

      - name: Create snyk-results
        run: mkdir -p snyk-results

      - name: Authenticate with Snyk
        run: snyk auth ${{ secrets.SNYK_TOKEN }}
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Snyk Code (SAST) Test
        run: |
          snyk code test --all-projects \
            --file-glob='**/*.{js,ts,vue,py}' \
            --json > snyk-results/code-vulns.json || true
        working-directory: ${{ github.workspace }}

      - name: Convert Snyk to Sonar Result
        run: python .github/scripts/convert_snyk_sonarqube.py || true

      # ========== SEMGREP (ENHANCED) ==========
      - name: Install Semgrep
        run: pip install semgrep

      - name: Run Semgrep Security Scan
        run: |
          mkdir -p semgrep-results
          semgrep scan \
            --config auto \
            --config p/security-audit \
            --config p/secrets \
            --config p/owasp-top-ten \
            --json -o semgrep-results/semgrep-report.json \
            --sarif -o semgrep-results/semgrep.sarif \
            --severity ERROR \
            --severity WARNING
        continue-on-error: true

      # ========== SQL INJECTION DETECTION (OTS-RSK-00055) ==========
      - name: Semgrep SQL Injection Detection
        run: |
          echo "Scanning for SQL injection vulnerabilities..."
          semgrep scan \
            --config "r/python.sqlalchemy.security" \
            --config "r/python.django.security.injection.sql" \
            --json -o semgrep-results/sql-injection.json \
            --severity ERROR || true
          
          # Check if SQL injection vulnerabilities found
          if [ -f semgrep-results/sql-injection.json ]; then
            SQL_COUNT=$(jq '.results | length' semgrep-results/sql-injection.json)
            if [ "$SQL_COUNT" -gt 0 ]; then
              echo "❌ Found $SQL_COUNT potential SQL injection vulnerabilities"
              jq '.results[] | {file: .path, line: .start.line, message: .extra.message}' \
                semgrep-results/sql-injection.json
              exit 1
            fi
          fi
          echo "✅ No SQL injection vulnerabilities detected"

      - name: Upload Semgrep Results Artifact
        uses: actions/upload-artifact@c7d193f32edcb7bfad88892161225aeda64e9392  # v4.0.0
        if: always()
        with:
          name: semgrep-security-results
          path: semgrep-results/
          retention-days: 30

      - name: Check Semgrep Critical Findings
        run: |
          if [ -f semgrep-results/semgrep-report.json ]; then
            CRITICAL_COUNT=$(jq '[.results[] | select(.extra.severity == "ERROR")] | length' \
              semgrep-results/semgrep-report.json)
            echo "Critical/High severity findings: $CRITICAL_COUNT"
            
            if [ "$CRITICAL_COUNT" -gt 0 ]; then
              echo "❌ Found $CRITICAL_COUNT critical security issues!"
              echo "Review findings in artifacts or SonarQube"
              exit 1
            else
              echo "✅ No critical security issues found"
            fi
          fi
        continue-on-error: false

      - name: Convert Semgrep report to SonarQube format
        if: always()
        run: |
          python3 - <<'EOF'
          import json
          try:
              with open("semgrep-results/semgrep-report.json") as f:
                  data = json.load(f)
              issues = []
              for result in data.get("results", []):
                  severity_map = {
                      "ERROR": "CRITICAL",
                      "WARNING": "MAJOR",
                      "INFO": "MINOR"
                  }
                  semgrep_severity = result.get("extra", {}).get("severity", "INFO")
                  sonar_severity = severity_map.get(semgrep_severity, "MAJOR")

                  issues.append({
                      "engineId": "semgrep",
                      "ruleId": result["check_id"],
                      "severity": sonar_severity,
                      "type": "VULNERABILITY",
                      "primaryLocation": {
                          "message": result.get("extra", {}).get("message", "Security issue detected"),
                          "filePath": result["path"],
                          "textRange": {
                              "startLine": result["start"]["line"],
                              "endLine": result["end"]["line"]
                          }
                      }
                  })
              with open("semgrep-results/sonar-semgrep-report.json", "w") as out:
                  json.dump({"issues": issues}, out, indent=2)
              print(f"✅ Converted {len(issues)} findings to SonarQube format")
          except Exception as e:
              print(f"⚠️ Error converting Semgrep results: {e}")
              with open("semgrep-results/sonar-semgrep-report.json", "w") as out:
                  json.dump({"issues": []}, out)
          EOF

      # ========== BANDIT ==========
      - name: Install Bandit
        run: pip install bandit

      - name: Run Bandit Security Scan
        run: |
          mkdir -p bandit-results
          
          # Run Bandit with SQL injection checks (B608, B609)
          bandit --configfile .github/config/bandit.yaml \
            -r app/ \
            -f json \
            -o bandit-results/bandit-output.json \
            --tests B608,B609 || true
          
          # Also run full Bandit scan
          bandit --configfile .github/config/bandit.yaml \
            -r . \
            -f json \
            -o bandit-results/bandit-full.json || true

      - name: Convert Bandit output to SonarQube generic issue format
        run: |
          python3 - <<'EOF'
          import json
          
          try:
              with open('bandit-results/bandit-full.json') as f:
                  bandit_data = json.load(f)
          except FileNotFoundError:
              with open('bandit-results/bandit-output.json') as f:
                  bandit_data = json.load(f)

          issues = []
          for result in bandit_data.get('results', []):
              # Map Bandit severity to SonarQube
              severity_map = {
                  'HIGH': 'CRITICAL',
                  'MEDIUM': 'MAJOR',
                  'LOW': 'MINOR'
              }
              
              issues.append({
                  "engineId": "bandit",
                  "ruleId": result.get("test_id"),
                  "type": "VULNERABILITY",
                  "severity": severity_map.get(result.get("issue_severity", "MEDIUM"), "MAJOR"),
                  "primaryLocation": {
                      "message": result.get("issue_text"),
                      "filePath": result.get("filename"),
                      "textRange": {
                          "startLine": result.get("line_number"),
                          "endLine": result.get("line_number"),
                      },
                  }
              })

          with open('bandit-results/sonar-bandit-report.json', 'w') as f:
              json.dump({"issues": issues}, f, indent=2)
          
          print(f"✅ Converted {len(issues)} Bandit findings to SonarQube format")
          EOF

      # ========== FLAKE8 ==========
      - name: Install Flake8
        run: pip install flake8

      - name: Run Flake8
        run: |
          flake8 --count --max-line-length=120 \
            --format=pylint \
            --output-file=OMEA-Backend-flake8-report.txt || true
        continue-on-error: true

      - name: Upload Flake8 report as artifact
        uses: actions/upload-artifact@c7d193f32edcb7bfad88892161225aeda64e9392
        with:
          name: OMEA-Backend-flake8-report
          path: OMEA-Backend-flake8-report.txt
          retention-days: 30

      # ========== DEPENDENCY-CHECK ==========
      - name: Cache Dependency-Check Database
        uses: actions/cache@704facf57e6136b1bc63b828d79edcd491f0ee84
        with:
          path: dependency-check/dependency-check/data
          key: dependency-check-data-${{ github.run_id }}
          restore-keys: |
            dependency-check-data-

      - name: Download Dependency-Check
        run: |
          if [ ! -d "dependency-check" ]; then
            wget https://github.com/dependency-check/DependencyCheck/releases/download/v12.1.6/dependency-check-12.1.6-release.zip
            unzip dependency-check-12.1.6-release.zip -d dependency-check
            rm dependency-check-12.1.6-release.zip
          fi

      - name: Update Dependency-Check
        run: ./dependency-check/dependency-check/bin/dependency-check.sh --updateonly || true

      - name: Run Dependency-Check
        shell: bash {0}
        run: |
          ./dependency-check/dependency-check/bin/dependency-check.sh \
            --format "JSON" \
            --out dependency-check-report.json \
            --disableCentral \
            --disableAssembly \
            --enableExperimental \
            -s ${{ github.workspace }} \
            --exclude "**/dependency-check/**" \
            --exclude "**/node_modules/**" \
            --exclude "**/.venv/**" || true

      - name: Convert Dependency-Check to Sonar Format
        run: |
          if [ -f dependency-check-report.json ]; then
            python .github/scripts/dependency-check-to-sonar.py
          else
            echo '{"issues":[]}' > dependency-sonar-external-report.json
          fi

      # ========== LICENSE COMPLIANCE (FMEA-PILLOW-005) ==========
      - name: Check License Compliance
        run: |
          pip install pip-licenses liccheck
          
          # Generate license report
          pip-licenses --format=json > licenses.json
          pip-licenses --format=markdown > licenses.md
          
          # Check for LGPL licenses
          python3 - <<'EOF'
          import json
          import sys
          
          with open('licenses.json') as f:
              licenses = json.load(f)
          
          lgpl_packages = []
          problematic_licenses = ['LGPL', 'GPL', 'AGPL']
          
          for pkg in licenses:
              license_name = pkg.get('License', '')
              if any(lic in license_name.upper() for lic in problematic_licenses):
                  lgpl_packages.append({
                      'name': pkg.get('Name'),
                      'version': pkg.get('Version'),
                      'license': license_name
                  })
          
          if lgpl_packages:
              print(f"⚠️ Found {len(lgpl_packages)} packages with copyleft licenses:")
              for pkg in lgpl_packages:
                  print(f"  - {pkg['name']} {pkg['version']}: {pkg['license']}")
              print("\nEnsure dynamic linking compliance for LGPL packages")
              print("Document license compliance in project documentation")
          else:
              print("✅ No LGPL/GPL license conflicts detected")
          EOF

      - name: Upload License Report
        uses: actions/upload-artifact@c7d193f32edcb7bfad88892161225aeda64e9392
        with:
          name: license-compliance-report
          path: |
            licenses.json
            licenses.md
          retention-days: 90

  # ========== SONARQUBE ANALYSIS ==========
  sonarqube-analysis:
    name: SonarQube Analysis
    needs: [security-tests, api-contract-validation, security-scanning]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
        with:
          fetch-depth: 0

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true

      - name: Run SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
          SONAR_SCANNER_OPTS: >
            -Dsonar.sources=app
            -Dsonar.tests=tests
            -Dsonar.exclusions=dependency-check/dependency-check/data/**,**/snyk-results/**,**/semgrep-results/**,**/.github/scripts,**/tests/**
            -Dsonar.test.inclusions=tests/**/*.py
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.python.flake8.reportPaths=OMEA-Backend-flake8-report.txt
            -Dsonar.externalIssuesReportPaths=semgrep-results/sonar-semgrep-report.json,bandit-results/sonar-bandit-report.json,dependency-sonar-external-report.json,snyk-results/snyk-sonarqube-report.json
            -Dsonar.sarifReportPaths=semgrep-results/semgrep.sarif

      - name: SonarQube Quality Gate Check
        uses: sonarsource/sonarqube-quality-gate-action@master
        timeout-minutes: 5
        continue-on-error: false
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # ========== IMAGE PROCESSING SECURITY (FMEA-PILLOW-002) ==========
  image-security-check:
    name: Image Processing Security
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11

      - name: Set up Python
        uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236
        with:
          python-version: '3.12.9'

      - name: Check Image Processing Libraries
        run: |
          pip install -r requirements.txt || true
          
          python3 - <<'EOF'
          import sys
          
          try:
              import PIL
              print(f"Pillow version: {PIL.__version__}")
              
              # Check if Pillow version has known CVEs
              version = PIL.__version__
              print(f"✅ Pillow {version} installed")
          except ImportError:
              print("⚠️ Pillow not installed")
          
          try:
              import cv2
              print(f"OpenCV version: {cv2.__version__}")
          except ImportError:
              print("ℹ️ OpenCV not installed")
          
          print("\n✅ Image processing library versions logged")
          print("Vulnerabilities will be caught by Snyk/Dependency-Check scans")
          EOF

      - name: Test Image Processing Sandboxing
        run: |
          if [ -d "tests/security" ] && [ -f "tests/security/test_image_sandbox.py" ]; then
            pip install pytest
            pytest tests/security/test_image_sandbox.py -v || \
              echo "⚠️ Image sandboxing tests need implementation"
          else
            echo "ℹ️ Image sandboxing tests not yet implemented"
            echo "Required: Test image uploads are processed in isolated environment"
          fi
